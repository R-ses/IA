{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica 8  Aplicacion de redes neuronales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD_DB\n",
    "columns_names = ['Target','Alcohol','Malic acid','Ash','Alcalinity of ash',\n",
    "                 'Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols',\n",
    "                 'Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines',\n",
    "                 'Proline']\n",
    "ds = pd.read_csv('../datasets/Wine/wine.csv', header=-1, names=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT_CONFUSION_MATRIX [Funcion extra]\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop(columns=['Target'])\n",
    "#X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ds['Target']\n",
    "#y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x792 with 0 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x792 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SCALER \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ds)\n",
    "df_corr = pd.DataFrame(scaler.transform(ds), columns = ds.columns)\n",
    "corr = df_corr.corr()\n",
    "plt.figure(figsize=(25,11))\n",
    "#sns.heatmap(corr, cmap = 'inferno')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_DEFINITION \n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    #Capa de entrada y oculta\n",
    "    model.add(Dense(1, input_shape=(nb_inputs,), kernel_initializer='random_uniform'))\n",
    "    N = 10\n",
    "    #CAPAS\n",
    "    model.add(Dense(N, activation ='exponential'))\n",
    "    model.add(Dense(N, ))\n",
    "    #model.add(Dense(N, ))\n",
    "    #model.add(Dense(N, ))\n",
    "    \n",
    "    \n",
    "    #Capa de salida\n",
    "    #Neuronas de salida igual a la cantidad de etiquetas\n",
    "    model.add(Dense(nb_targets))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #Método de aprendizaje\n",
    "    #opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)#Stochastic gradient descent \n",
    "    opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#ADAM\n",
    "    #opt = Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "    #opt = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    #opt = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    #opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    \n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy=0.889\n",
      "F1 score=0.889\n",
      "\n",
      "Fold 2\n",
      "Accuracy=0.911\n",
      "F1 score=0.911\n",
      "\n",
      "Fold 3\n",
      "Accuracy=0.911\n",
      "F1 score=0.911\n",
      "\n",
      "Fold 4\n",
      "Accuracy=0.953\n",
      "F1 score=0.953\n",
      "\n",
      "AVERAGE\n",
      "Accuracy=0.916\n",
      "F1 score=0.916\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "\n",
    "#kf = StratifiedKFold(n_splits=5)\n",
    "nb_inputs = len(list(X.columns))\n",
    "nb_targets = len(list(y.unique()))\n",
    "\n",
    "X[:] = scaler.fit_transform(X.loc[:])\n",
    "#NUM_ITER\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "i = 0\n",
    "avg_acc = []\n",
    "avg_f1 = []\n",
    "for idx_train, idx_test in kf.split(X,y):\n",
    "    X_train = X.loc[idx_train]\n",
    "    X_test = X.loc[idx_test]\n",
    "    y_train = y.loc[idx_train]\n",
    "    y_test = y.loc[idx_test]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    nn_model = get_model()\n",
    "\n",
    "\n",
    "    #pd.get_dummies(y_train) Crea representación One-hot-encoding\n",
    "    \n",
    "    Niter = 25\n",
    "    for PN in (range(0,Niter)):\n",
    "        nn_model.fit(X_train, pd.get_dummies(y_train), epochs=150, verbose=False)\n",
    "        #print(\"{} \".format((PN+1)/Niter))\n",
    "\n",
    "    y_pred = nn_model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)+1\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    avg_acc.append(acc)\n",
    "    avg_f1.append(f1)\n",
    "    print(\"Fold {}\\nAccuracy={:.3f}\\nF1 score={:.3}\\n\".format(i+1,acc,f1))\n",
    "    #plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes=['Low', 'Medium', 'High'],\n",
    "    #                  title='Confusion matrix, without normalization')\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "print(\"AVERAGE\\nAccuracy={:.3f}\\nF1 score={:.3}\\n\".format(sum(avg_acc)/len(avg_acc),\n",
    "                                                          sum(avg_f1)/len(avg_f1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Classificacion_Bitacora.JPG'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
